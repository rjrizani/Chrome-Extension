{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_steps_with_tensor_flow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "ajVM7rkoYXeL",
        "ci1ISxxrZ7v0"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjrizani/Chrome-Extension/blob/master/first_steps_with_tensor_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JndnmDMp66FL"
      },
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "hMqWDc_m6rUC"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f3CKqFUqL2-"
      },
      "source": [
        "# Langkah Pertama dengan TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd2Zkk1LE2Zr"
      },
      "source": [
        "**Tujuan Pembelajaran:**\n",
        "  * Mempelajari konsep TensorFlow dasar\n",
        "  * Menggunakan kelas `LinearRegressor` di TensorFlow untuk memprediksi median harga perumahan, pada perincian blok kota, berdasarkan satu fitur masukan\n",
        "  * Mengevaluasi akurasi prediksi model menggunakan Akar Rataan Kuadrat Galat (ARKG)\n",
        "  * Meningkatkan akurasi model dengan menyesuaikan hyperparameter-nya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxiIKhP4E2Zr"
      },
      "source": [
        "[Data](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) didasarkan pada data sensus tahun 1990 dari California."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TjLjL9IU80G"
      },
      "source": [
        "## Penyiapan\n",
        "\n",
        "Di sel pertama ini, kita akan memuat library yang diperlukan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVFf5asKE2Zt"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipRyUHjhU80Q"
      },
      "source": [
        "Berikutnya, kita akan memuat kumpulan data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ivCDWnwE2Zx"
      },
      "source": [
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVk_qlG6U80j"
      },
      "source": [
        "Kita akan mengacak data tersebut, namun pastikan data tidak terkena efek pengurutan patologis yang dapat mengganggu performa Penurunan Gradien Stokastik. Selain itu, kita akan menskalakan `median_house_value` dalam satuan ribuan, sehingga dapat dipelajari sedikit lebih mudah dengan kecepatan pembelajaran dalam kisaran yang biasanya digunakan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0eVyguIU80m"
      },
      "source": [
        "california_housing_dataframe = california_housing_dataframe.reindex(\n",
        "    np.random.permutation(california_housing_dataframe.index))\n",
        "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
        "california_housing_dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzzlSs3PtTmt"
      },
      "source": [
        "## Periksa Data\n",
        "\n",
        "Ini adalah ide yang bagus untuk sedikit memahami data Anda sebelum menggunakannya.\n",
        "\n",
        "Kita akan mencetak ringkasan singkat dari beberapa statistik yang berguna di setiap kolom: jumlah contoh, rataan, simpangan baku, nilai maks, nilai min, dan berbagai kuantil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {},
        "id": "gzb10yoVrydW"
      },
      "source": [
        "california_housing_dataframe.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr6wYl2bt2Ep"
      },
      "source": [
        "## Buat Model Pertama\n",
        "\n",
        "Dalam latihan ini, kita akan mencoba memprediksi `median_house_value`, yang akan menjadi label (terkadang juga disebut target). Kita akan menggunakan `total_rooms` sebagai fitur masukan kita.\n",
        "\n",
        "**CATATAN:** Data kita berada di tingkat blok kota, sehingga fitur ini merepresentasikan jumlah total ruangan di blok tersebut.\n",
        "\n",
        "Untuk melatih model, kita akan menggunakan antarmuka [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) yang diberikan oleh TensorFlow [Estimator](https://www.tensorflow.org/get_started/estimator) API. API ini menangani banyak sistem model tingkat rendah, dan menampilkan metode yang nyaman untuk melakukan inferensi, evaluasi, dan pelatihan model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cpcsieFhsNI"
      },
      "source": [
        "### Langkah 1: Tentukan Fitur dan Konfigurasikan Kolom Fitur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL8-9d4ZJNR7"
      },
      "source": [
        "Untuk mengimpor data pelatihan ke TensorFlow, kita perlu menentukan jenis data apa yang ada dalam setiap fitur. Ada dua jenis data utama yang akan kita gunakan dalam latihan ini dan latihan berikutnya:\n",
        "\n",
        "* **Data Kategorikal**: Data yang bersifat tekstual. Dalam latihan ini, kumpulan data perumahan kita tidak berisi fitur kategoris apa pun, tetapi contoh yang mungkin Anda lihat adalah gaya rumah dan kata dalam iklan real estat.\n",
        "\n",
        "* **Data Numerik**: Data yang berupa bilangan (bulat atau pecahan) dan data yang ingin Anda perlakukan sebagai bilangan. Seperti yang akan kita bahas lebih lanjut, terkadang Anda mungkin ingin memperlakukan data numerik (misalnya kode pos) selayaknya data kategorikal.\n",
        "\n",
        "Di TensorFlow, kita menunjukkan jenis data fitur menggunakan konstruksi yang disebut **kolom fitur**. Kolom fitur hanya menyimpan deskripsi data fitur dan tidak berisi data fitur itu sendiri.\n",
        "\n",
        "Untuk memulainya, kita hanya akan menggunakan satu fitur masukan numerik, yaitu `total_rooms`. Kode berikut mengambil data `total_rooms` dari `california_housing_dataframe` dan mendefinisikan kolom fitur menggunakan `numeric_column`, yang menentukan datanya berupa angka:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhEbFCZ86cDZ"
      },
      "source": [
        "# Define the input feature: total_rooms.\n",
        "my_feature = california_housing_dataframe[[\"total_rooms\"]]\n",
        "\n",
        "# Configure a numeric feature column for total_rooms.\n",
        "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_3S8teX7Rd2"
      },
      "source": [
        "**CATATAN:** Bentuk data `total_rooms` kita adalah array satu dimensi (daftar jumlah total ruangan untuk setiap blok). Ini adalah bentuk default untuk `numeric_column`, sehingga kita tidak harus meneruskannya sebagai argumen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMl3qrU5MGV6"
      },
      "source": [
        "### Langkah 2: Tentukan Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw4nrfcB7kyk"
      },
      "source": [
        "Selanjutnya, kita akan menentukan target, yaitu `median_house_value`. Sekali lagi, kita dapat mengambilnya dari `california_housing_dataframe`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1NvvNkH8Kbt"
      },
      "source": [
        "# Define the label.\n",
        "targets = california_housing_dataframe[\"median_house_value\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M-rTFHL2UkA"
      },
      "source": [
        "### Langkah 3: Konfigurasikan LinearRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUfGQUNp7jdL"
      },
      "source": [
        "Selanjutnya, kita akan mengonfigurasi model regresi linear menggunakan LinearRegressor. Kita akan melatih model ini menggunakan `GradientDescentOptimizer`, yang menerapkan Tumpukan Mini Penurunan Gradien Stokastik (PGS). Argumen `learning_rate` mengontrol ukuran langkah gradien.\n",
        "\n",
        "**CATATAN:** Agar aman, kita juga menerapkan [pemotongan gradien](https://developers.google.com/machine-learning/glossary/#gradient_clipping) ke pengoptimal menggunakan `clip_gradients_by_norm`. Pemotongan gradien memastikan ukuran gradien tidak terlalu besar selama pelatihan, yang dapat menyebabkan kegagalan pada penurunan gradien. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubhtW-NGU802"
      },
      "source": [
        "# Use gradient descent as the optimizer for training the model.\n",
        "my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "# Configure the linear regression model with our feature columns and optimizer.\n",
        "# Set a learning rate of 0.0000001 for Gradient Descent.\n",
        "linear_regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=feature_columns,\n",
        "    optimizer=my_optimizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0IztwdK2f3F"
      },
      "source": [
        "### Langkah 4: Tentukan Fungsi Masukan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5M5j6xSCHxx"
      },
      "source": [
        "Untuk mengimpor data perumahan di California ke `LinearRegressor`, kita perlu mendefinisikan fungsi masukan, yang menginstruksikan TensorFlow bagaimana cara melakukan pra-pemrosesan terhadap data, serta cara menumpuk, mengacak, dan mengulanginya selama pelatihan model.\n",
        "\n",
        "Pertama, kita akan mengonversi data fitur *pandas* menjadi kamus array NumPy. Kemudian, kita dapat menggunakan [API Kumpulan Data](https://www.tensorflow.org/programmers_guide/datasets) TensorFlow untuk membuat objek kumpulan data dari data tersebut, lalu membaginya menjadi tumpukan `batch_size`, yang akan diulang untuk jumlah iterasi pelatihan (num_epochs) yang ditentukan.\n",
        "\n",
        "**CATATAN:** Ketika nilai default `num_epochs=None` diteruskan ke `repeat()`, data masukan akan diulang tanpa batas.\n",
        "\n",
        "Berikutnya, jika `shuffle` disetel ke `True`, kita akan mengacak data sehingga diteruskan ke model secara acak selama pelatihan. Argumen `buffer_size` menentukan ukuran kumpulan data tempat `shuffle` akan mengambil sampel secara acak.\n",
        "\n",
        "Terakhir, fungsi masukan kita akan membuat iterator untuk kumpulan data dan mengembalikan tumpukan data berikutnya ke LinearRegressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKZ9zNcHJtwc"
      },
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a linear regression model of one feature.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "  \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(buffer_size=10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwa6UeA1V5F_"
      },
      "source": [
        "**CATATAN:** Kita akan terus menggunakan fungsi masukan yang sama ini di latihan selanjutnya. Untuk dokumentasi mendetail tentang fungsi masukan dan `Dataset` API, lihat [Panduan Pemrogram TensorFlow](https://www.tensorflow.org/programmers_guide/datasets)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YS50CQb2ooO"
      },
      "source": [
        "### Langkah 5: Latih Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP92XkzhU803"
      },
      "source": [
        "Kita sekarang dapat memanggil `train()` pada `linear_regressor` untuk melatih model. Kita akan menggabungkan `my_input_fn` dalam `lambda` sehingga kita dapat meneruskannya dalam `my_feature` dan `target` sebagai argumen (lihat [tutorial fungsi masukan TensorFlow](https://www.tensorflow.org/get_started/input_fn#passing_input_fn_data_to_your_model) ini untuk detail selengkapnya), dan untuk memulainya, kita akan melatihnya 100 langkah."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M-Kt6w8U803"
      },
      "source": [
        "_ = linear_regressor.train(\n",
        "    input_fn = lambda:my_input_fn(my_feature, targets),\n",
        "    steps=100\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nwxqxlx2sOv"
      },
      "source": [
        "### Langkah 6: Evaluasi Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoDaF2dlJQG5"
      },
      "source": [
        "Mari buat prediksi tentang data pelatihan tersebut, untuk melihat seberapa baik model menyesuaikannya selama pelatihan.\n",
        "\n",
        "**CATATAN:** Error pelatihan mengukur seberapa baik model Anda menyesuaikan dengan data pelatihan, tetapi **_tidak_** mengukur seberapa baik model Anda **_menggeneralisasi ke data baru_**. Dalam latihan selanjutnya, Anda akan mempelajari cara membagi data untuk mengevaluasi kemampuan model untuk melakukan generalisasi.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDIxp6vcU809"
      },
      "source": [
        "# Create an input function for predictions.\n",
        "# Note: Since we're making just one prediction for each example, we don't \n",
        "# need to repeat or shuffle the data here.\n",
        "prediction_input_fn =lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)\n",
        "\n",
        "# Call predict() on the linear_regressor to make predictions.\n",
        "predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
        "\n",
        "# Format predictions as a NumPy array, so we can calculate error metrics.\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "# Print Mean Squared Error and Root Mean Squared Error.\n",
        "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
        "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
        "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
        "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKWstXXPzOVz"
      },
      "source": [
        "Apakah model ini sudah baik? Bagaimana Anda akan menilai seberapa besar error ini?\n",
        "\n",
        "Rataan Kuadrat Galat (RKG) bisa sulit diinterpretasikan, sehingga kita sering menggunakan Akar Rataan Kuadrat Galat (ARKG) sebagai gantinya. Kelebihan ARKG adalah dapat diinterpretasikan pada skala yang sama dengan target aslinya.\n",
        "\n",
        "Mari bandingkan ARKG dengan perbedaan nilai min dan maks dari target kita:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UwqGbbxP53O"
      },
      "source": [
        "min_house_value = california_housing_dataframe[\"median_house_value\"].min()\n",
        "max_house_value = california_housing_dataframe[\"median_house_value\"].max()\n",
        "min_max_difference = max_house_value - min_house_value\n",
        "\n",
        "print(\"Min. Median House Value: %0.3f\" % min_house_value)\n",
        "print(\"Max. Median House Value: %0.3f\" % max_house_value)\n",
        "print(\"Difference between Min. and Max.: %0.3f\" % min_max_difference)\n",
        "print(\"Root Mean Squared Error: %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JigJr0C7Pzit"
      },
      "source": [
        "Error kita mencakup hampir setengah dari kisaran nilai target. Bisakah kita melakukannya dengan lebih baik?\n",
        "\n",
        "Pertanyaan ini sering diajukan kepada setiap developer model. Mari kembangkan beberapa strategi dasar untuk mengurangi error model.\n",
        "\n",
        "Langkah pertama yang dapat kita lakukan adalah melihat seberapa baik prediksi kita menyesuaikan dengan target, dalam hal statistik ringkasan secara keseluruhan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {},
        "id": "941nclxbzqGH"
      },
      "source": [
        "calibration_data = pd.DataFrame()\n",
        "calibration_data[\"predictions\"] = pd.Series(predictions)\n",
        "calibration_data[\"targets\"] = pd.Series(targets)\n",
        "calibration_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2-bf8Hq36y8"
      },
      "source": [
        "Oke, mungkin informasi ini bermanfaat. Bagaimana nilai rataan jika dibandingkan dengan ARKG model? Bagaimana dengan kuantil yang beragam?\n",
        "\n",
        "Kita juga dapat menggambarkan data dan garis yang telah dipelajari. Perlu diingat bahwa regresi linear pada satu fitur dapat diambil sebagai masukan pemetaan garis *x* ke keluaran *y*.\n",
        "\n",
        "Pertama, kita akan mendapatkan sampel acak yang seragam dari data, sehingga kita dapat membuat bagan sebar yang bisa dibaca."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGRIi3mAU81H"
      },
      "source": [
        "sample = california_housing_dataframe.sample(n=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-JwuJBKU81J"
      },
      "source": [
        "Selanjutnya, kita akan menggambarkan garis yang telah dipelajari, menggambar dari bobot fitur dan istilah bias model, bersama dengan bagan sebar. Garisnya akan ditunjukkan dengan warna merah."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {},
        "id": "7G12E76-339G"
      },
      "source": [
        "# Get the min and max total_rooms values.\n",
        "x_0 = sample[\"total_rooms\"].min()\n",
        "x_1 = sample[\"total_rooms\"].max()\n",
        "\n",
        "# Retrieve the final weight and bias generated during training.\n",
        "weight = linear_regressor.get_variable_value('linear/linear_model/total_rooms/weights')[0]\n",
        "bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
        "\n",
        "# Get the predicted median_house_values for the min and max total_rooms values.\n",
        "y_0 = weight * x_0 + bias \n",
        "y_1 = weight * x_1 + bias\n",
        "\n",
        "# Plot our regression line from (x_0, y_0) to (x_1, y_1).\n",
        "plt.plot([x_0, x_1], [y_0, y_1], c='r')\n",
        "\n",
        "# Label the graph axes.\n",
        "plt.ylabel(\"median_house_value\")\n",
        "plt.xlabel(\"total_rooms\")\n",
        "\n",
        "# Plot a scatter plot from our data sample.\n",
        "plt.scatter(sample[\"total_rooms\"], sample[\"median_house_value\"])\n",
        "\n",
        "# Display graph.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0lRt4USU81L"
      },
      "source": [
        "Baris awal ini terlihat terlalu jauh. Lihat apakah Anda dapat melihat kembali statistik ringkasan dan melihat informasi yang sama yang dienkode di sana.\n",
        "\n",
        "Bersama, pemeriksaan awal ini menyarankan bahwa kita mungkin dapat menemukan garis yang jauh lebih baik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZWF67uv0HTG"
      },
      "source": [
        "## Sesuaikan Hyperparameter Model\n",
        "Untuk latihan ini, kita telah menempatkan semua kode di atas dalam satu fungsi untuk kenyamanan. Anda dapat memanggil fungsi dengan parameter yang berbeda untuk melihat efeknya.\n",
        "\n",
        "Dalam fungsi ini, kita akan memproses dalam 10 periode yang terbagi secara merata sehingga kita dapat mengamati peningkatan model pada setiap periode.\n",
        "\n",
        "Untuk setiap periode, kita menghitung dan membuat grafik kerugian pelatihan. Tindakan ini dapat membantu Anda menilai saat sebuah model dikonvergensi, atau jika model perlu lebih banyak iterasi.\n",
        "\n",
        "Kita juga akan menggambar bobot fitur dan nilai bias yang dipelajari oleh model dari waktu ke waktu. Tindakan ini adalah cara alternatif untuk melihat bagaimana model dikonvergensi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgSMeD5UU81N"
      },
      "source": [
        "def train_model(learning_rate, steps, batch_size, input_feature=\"total_rooms\"):\n",
        "  \"\"\"Trains a linear regression model of one feature.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    input_feature: A `string` specifying a column from `california_housing_dataframe`\n",
        "      to use as input feature.\n",
        "  \"\"\"\n",
        "  \n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "\n",
        "  my_feature = input_feature\n",
        "  my_feature_data = california_housing_dataframe[[my_feature]]\n",
        "  my_label = \"median_house_value\"\n",
        "  targets = california_housing_dataframe[my_label]\n",
        "\n",
        "  # Create feature columns.\n",
        "  feature_columns = [tf.feature_column.numeric_column(my_feature)]\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda:my_input_fn(my_feature_data, targets, batch_size=batch_size)\n",
        "  prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
        "  \n",
        "  # Create a linear regressor object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_regressor = tf.estimator.LinearRegressor(\n",
        "      feature_columns=feature_columns,\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "\n",
        "  # Set up to plot the state of our model's line each period.\n",
        "  plt.figure(figsize=(15, 6))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title(\"Learned Line by Period\")\n",
        "  plt.ylabel(my_label)\n",
        "  plt.xlabel(my_feature)\n",
        "  sample = california_housing_dataframe.sample(n=300)\n",
        "  plt.scatter(sample[my_feature], sample[my_label])\n",
        "  colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  root_mean_squared_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.\n",
        "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
        "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "    \n",
        "    # Compute loss.\n",
        "    root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(predictions, targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, root_mean_squared_error))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    root_mean_squared_errors.append(root_mean_squared_error)\n",
        "    # Finally, track the weights and biases over time.\n",
        "    # Apply some math to ensure that the data and line are plotted neatly.\n",
        "    y_extents = np.array([0, sample[my_label].max()])\n",
        "    \n",
        "    weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0]\n",
        "    bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
        "\n",
        "    x_extents = (y_extents - bias) / weight\n",
        "    x_extents = np.maximum(np.minimum(x_extents,\n",
        "                                      sample[my_feature].max()),\n",
        "                           sample[my_feature].min())\n",
        "    y_extents = weight * x_extents + bias\n",
        "    plt.plot(x_extents, y_extents, color=colors[period]) \n",
        "  print(\"Model training finished.\")\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.xlabel('Periods')\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(root_mean_squared_errors)\n",
        "\n",
        "  # Output a table with calibration data.\n",
        "  calibration_data = pd.DataFrame()\n",
        "  calibration_data[\"predictions\"] = pd.Series(predictions)\n",
        "  calibration_data[\"targets\"] = pd.Series(targets)\n",
        "  display.display(calibration_data.describe())\n",
        "\n",
        "  print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg8A4ArBU81Q"
      },
      "source": [
        "## Tugas 1: Dapatkan nilai ARKG sebesar 180 atau Lebih Rendah\n",
        "\n",
        "Sesuaikan hyperparameter model untuk meningkatkan kerugian dan sesuaikan distribusi target dengan lebih baik. Jika setelah 5 menit atau lebih, Anda mengalami kesulitan mencapai nilai ARKG sebesar 180, lihat solusi untuk kombinasi yang memungkinkan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {},
        "id": "UzoZUSdLIolF"
      },
      "source": [
        "train_model(\n",
        "    learning_rate=0.00001,\n",
        "    steps=100,\n",
        "    batch_size=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajVM7rkoYXeL"
      },
      "source": [
        "### Solusi\n",
        "\n",
        "Klik di bawah untuk mendapatkan satu solusi yang memungkinkan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3zmldDwYy5c"
      },
      "source": [
        "train_model(\n",
        "    learning_rate=0.00002,\n",
        "    steps=500,\n",
        "    batch_size=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8H0_D4vYa49"
      },
      "source": [
        "Ini hanyalah satu konfigurasi yang memungkinkan; mungkin ada kombinasi setelan lainnya yang juga memberikan hasil yang baik. Perhatikan bahwa pada umumnya, latihan ini bukanlah tentang menemukan setelan *terbaik*, namun untuk membantu mengasah intuisi Anda tentang bagaimana penyesuaian terhadap konfigurasi model memengaruhi kualitas prediksi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU5sLyYTqzqL"
      },
      "source": [
        "### Apakah Ada Heuristik Standar untuk Penyesuaian Model?\n",
        "\n",
        "Pertanyaan ini sering diajukan. Jawaban singkatnya, efek dari hyperparameter yang berbeda bergantung pada data. Sehingga tidak ada aturan yang tetap dan pasti; Anda harus menguji data tersebut.\n",
        "\n",
        "Dengan demikian, berikut adalah beberapa aturan praktis yang dapat membantu memandu Anda:\n",
        "\n",
        " * Error pelatihan harus berkurang dengan stabil, tajam di awal, namun akhirnya harus berkurang dengan stabil seiring konvergensi pelatihan.\n",
        " * Jika pelatihan tidak dikonvergensi, coba jalankan dalam durasi yang lebih lama.\n",
        " * Jika error pelatihan berkurang sangat lambat, meningkatkan kecepatan pembelajaran dapat membantu menguranginya dengan lebih cepat.\n",
        "   * Namun terkadang hal sebaliknya dapat terjadi jika kecepatan pembelajaran terlalu tinggi.\n",
        " * Jika error pelatihan sangat bervariasi, cobalah mengurangi kecepatan pembelajaran.\n",
        "   * Kecepatan pembelajaran yang lebih rendah, ditambah dengan jumlah langkah yang lebih besar atau ukuran tumpukan yang lebih besar, sering kali menjadi kombinasi yang baik.\n",
        " * Ukuran tumpukan yang sangat kecil juga dapat menyebabkan ketidakstabilan. Pertama, cobalah nilai yang lebih besar seperti 100 atau 1.000, lalu turunkan hingga Anda melihat degradasi.\n",
        "\n",
        "Sekali lagi, jangan terlalu mengikuti aturan praktis ini, karena efeknya tergantung pada data. Selalu lakukan uji coba dan verifikasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpV-uF_cBCBU"
      },
      "source": [
        "## Tugas 2: Cobalah Fitur yang Berbeda\n",
        "\n",
        "Lihat apakah Anda dapat melakukannya lebih baik dengan mengganti fitur `total_rooms` dengan fitur `population`.\n",
        "\n",
        "Jangan menghabiskan waktu lebih dari 5 menit untuk melakukan tindakan ini."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMyOxzb0ZlAH"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci1ISxxrZ7v0"
      },
      "source": [
        "### Solusi\n",
        "\n",
        "Klik di bawah untuk mendapatkan satu solusi yang memungkinkan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjdQQCduZ7BV"
      },
      "source": [
        "train_model(\n",
        "    learning_rate=0.00002,\n",
        "    steps=1000,\n",
        "    batch_size=5,\n",
        "    input_feature=\"population\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}